import os
import json
from pathlib import Path
from collections import Counter
import ast
import tkinter as tk
from tkinter import filedialog, messagebox, ttk
import tkinter.font as tkfont

def get_repo_name(repo_path):
    """Get the name of the selected repository folder."""
    return os.path.basename(repo_path)

def extract_dependencies(file_path):
    """Extract dependencies from Python and JavaScript files."""
    dependencies = []
    try:
        with open(file_path, "r", encoding="utf-8") as file:
            for line in file:
                if line.strip().startswith(("import ", "from ", "require(", "import ")):
                    dependencies.append(line.strip())
    except Exception as e:
        dependencies.append(f"Error reading dependencies: {e}")
    return dependencies

def analyze_python_file(file_path):
    """Extract functions and classes from a Python file."""
    functions = []
    classes = []
    try:
        with open(file_path, "r", encoding="utf-8") as file:
            tree = ast.parse(file.read())
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    functions.append(node.name)
                elif isinstance(node, ast.ClassDef):
                    classes.append(node.name)
    except Exception as e:
        return {"error": str(e)}
    return {"functions": functions, "classes": classes}

def generate_directory_structure(root_dir):
    """Generate a tree-like structure of the directory."""
    structure = []
    for root, dirs, files in os.walk(root_dir):
        relative_path = os.path.relpath(root, root_dir)
        structure.append(f"{relative_path}/")
        for file in files:
            structure.append(f"  {relative_path}/{file}")
    return "\n".join(structure)

def identify_entry_points(repo_path):
    """Identify possible entry points to the application."""
    entry_points = []
    for root, _, files in os.walk(repo_path):
        for file in files:
            if file in ["main.py", "app.py", "index.js", "server.js", "run.py", "start.py"]:
                entry_points.append(os.path.relpath(os.path.join(root, file), repo_path))
    return entry_points

def analyze_repo(repo_path, progress_var, status_var):
    """Main function to create both the merged file and insights file."""
    repo_name = get_repo_name(repo_path)
    merged_file = f"LLM-DocuMerge_{repo_name}.txt"
    insights_file = f"LLM-DocuMerge-Insights_{repo_name}.txt"
    
    status_var.set("Analyzing repository structure...")
    progress_var.set(10)
    window.update()

    # Initialize insights data
    insights = {
        "technologies": [],
        "directory_structure": "",
        "key_files": {},
        "code_statistics": {},
        "largest_files": [],
        "functions_and_classes": {},
        "file_sizes": {},
        "language_distribution": {},
        "entry_points": [],
        "readme_summary": "",
        "issues": []
    }

    # Get total file count for progress tracking
    total_files = 0
    for _, _, files in os.walk(repo_path):
        total_files += len(files)
    
    processed_files = 0

    # Add LLM instructions to beginning of insights file
    llm_instructions = """
=================================================================
REPOSITORY ANALYSIS REPORT
Generated by DocuMerge for LLMs
=================================================================

INSTRUCTIONS FOR THE LLM:

This file contains essential metadata extracted from a GitHub repository.
If you also have access to a file named "LLM-DocuMerge_[repo_name].txt", 
that contains the full content of all files in the repository.

HOW TO USE THESE FILES:
1. This insights file provides high-level understanding of the repository structure
2. The full merge file (if available) contains all code for detailed analysis

WHAT'S INCLUDED IN THIS REPORT:
- Directory Structure: Complete map of the repository's organization
- Technologies & Dependencies: External libraries and frameworks used
- Functions & Classes: Key programmatic elements across files
- Code Statistics: Lines of code and file sizes
- Language Distribution: Programming languages used and their prevalence
- Entry Points: Likely application starting points
- Key File Analysis: Important configuration and structural files

HOW TO ASSIST USERS:
1. If asked about repository structure or organization, use this insights file
2. If asked about specific code implementation, check if you have the merged file
3. If you only have this insights file, inform the user you understand the repository's
   structure but might need specific files for detailed code analysis
4. Guide users to relevant files based on your knowledge of the directory structure
5. Ask clarifying questions if the user's request is ambiguous:
   - "Which part of the codebase are you interested in?"
   - "Are you looking for implementation details or the overall architecture?"
   - "Would you like me to help locate specific files related to this functionality?"

This analysis was created by processing all files in the repository to help you
provide informed assistance without requiring the entire codebase to be loaded.
=================================================================

"""

    with open(merged_file, "w", encoding="utf-8") as merged_out, open(insights_file, "w", encoding="utf-8") as insights_out:
        # Add LLM instructions to insights file
        insights_out.write(llm_instructions)
        
        # Find entry points
        insights["entry_points"] = identify_entry_points(repo_path)
        
        for root, _, files in os.walk(repo_path):
            for file in files:
                file_path = os.path.join(root, file)
                relative_path = os.path.relpath(file_path, repo_path)
                
                # Update progress
                processed_files += 1
                progress_percent = int((processed_files / total_files) * 80) + 10
                progress_var.set(progress_percent)
                status_var.set(f"Processing {relative_path}...")
                window.update()
                
                # Skip the script itself
                if file == os.path.basename(__file__):
                    continue
                
                try:
                    # Write header to merged file
                    merged_out.write(f"\n{'=' * 50}\n{relative_path}\n{'=' * 50}\n")
                    
                    # Add README explanation to merged file
                    if file.lower() == "readme.md":
                        merged_out.write("\nThis file was generated by DocuMerge for LLMs, which consolidates repository files and analyzes structure.\n\n")
                        # Also store README content for insights
                        with open(file_path, "r", encoding="utf-8") as readme_file:
                            readme_content = readme_file.read()
                            # Store first 1000 characters as summary
                            insights["readme_summary"] = readme_content[:1000] + "..." if len(readme_content) > 1000 else readme_content
                    
                    # Write file content to merged file
                    with open(file_path, "r", encoding="utf-8") as infile:
                        content = infile.read()
                        merged_out.write(content)
                    
                    # Extract dependencies
                    if file.endswith((".py", ".js")):
                        insights["technologies"].extend(extract_dependencies(file_path))
                    
                    # Extract functions and classes
                    if file.endswith(".py"):
                        insights["functions_and_classes"][relative_path] = analyze_python_file(file_path)
                    
                    # Identify key configuration files
                    if file in ["package.json", "requirements.txt", "setup.py", "pyproject.toml", 
                              "Dockerfile", ".gitignore", "docker-compose.yml", ".env.example"]:
                        insights["key_files"][relative_path] = "Configuration file"
                    
                    # Count lines of code and file size
                    loc = len(content.splitlines())
                    size = os.path.getsize(file_path)
                    insights["code_statistics"][relative_path] = loc
                    insights["file_sizes"][relative_path] = size

                    # Determine language contribution
                    ext = Path(file).suffix
                    if ext not in insights["language_distribution"]:
                        insights["language_distribution"][ext] = 0
                    insights["language_distribution"][ext] += loc

                except Exception as e:
                    insights["issues"].append(f"Error processing {relative_path}: {e}")
        
        status_var.set("Finalizing report...")
        progress_var.set(90)
        window.update()
        
        # Sort largest files by LOC
        insights["largest_files"] = sorted(insights["code_statistics"].items(), key=lambda x: x[1], reverse=True)[:5]

        # Generate directory structure
        insights["directory_structure"] = generate_directory_structure(repo_path)

        # Write insights to file
        insights_out.write("\n===== REPOSITORY METRICS AND ANALYSIS =====\n\n")
        insights_out.write(f"Technologies and Dependencies:\n{json.dumps(list(set(insights['technologies'])), indent=2)}\n\n")
        insights_out.write(f"Directory Structure:\n{insights['directory_structure']}\n\n")
        insights_out.write(f"Functions and Classes:\n{json.dumps(insights['functions_and_classes'], indent=2)}\n\n")
        insights_out.write(f"Code Statistics:\n{json.dumps(insights['code_statistics'], indent=2)}\n\n")
        insights_out.write(f"File Sizes (bytes):\n{json.dumps(insights['file_sizes'], indent=2)}\n\n")
        insights_out.write(f"Largest Files (by LOC):\n{json.dumps(insights['largest_files'], indent=2)}\n\n")
        insights_out.write(f"Language Distribution:\n{json.dumps(insights['language_distribution'], indent=2)}\n\n")
        insights_out.write(f"Entry Points:\n{json.dumps(insights['entry_points'], indent=2)}\n\n")
        insights_out.write(f"Key Configuration Files:\n{json.dumps(insights['key_files'], indent=2)}\n\n")
        insights_out.write(f"README Summary:\n{insights['readme_summary']}\n\n")
        insights_out.write(f"Issues:\n{json.dumps(insights['issues'], indent=2)}\n\n")

    progress_var.set(100)
    status_var.set("Analysis complete!")
    window.update()
    
    output_path = os.path.abspath(os.path.dirname(merged_file))
    messagebox.showinfo("DocuMerge for LLMs", 
                       f"Analysis complete!\n\nFiles created:\n- {os.path.basename(merged_file)}\n- {os.path.basename(insights_file)}\n\nLocation: {output_path}")

def select_repo():
    """Open a file dialog to select the repository folder."""
    repo_path = filedialog.askdirectory(title="Select Repository Folder")
    if repo_path:
        progress_var.set(0)
        status_var.set("Starting analysis...")
        window.update()
        analyze_repo(repo_path, progress_var, status_var)

# Define wizard theme colors
arcane_purple = "#673AB7"
mystic_blue = "#3F51B5" 
potion_green = "#4CAF50"
scroll_parchment = "#FFF8E1"
wizard_dark = "#311B92"
spell_gold = "#FFD700"

# Create the main window
window = tk.Tk()
window.title("üßô‚Äç‚ôÇÔ∏è Cloud Potions: DocuMerge for LLMs üßô‚Äç‚ôÇÔ∏è")
window.geometry("650x500")
window.configure(bg=scroll_parchment)
window.resizable(True, True)

# Define fonts
title_font = tkfont.Font(family="Helvetica", size=18, weight="bold")
normal_font = tkfont.Font(family="Helvetica", size=12)
small_font = tkfont.Font(family="Helvetica", size=10)

# Create a header frame with arcane design
header_frame = tk.Frame(window, bg=arcane_purple, padx=10, pady=15)
header_frame.pack(fill=tk.X)

# Add title to the header with magical symbols
title_label = tk.Label(header_frame, 
                      text="üßô‚Äç‚ôÇÔ∏è Cloud Potions: DocuMerge for LLMs üîÆ",
                      font=title_font, 
                      fg="white", 
                      bg=arcane_purple)
title_label.pack()

# Create main content frame
content_frame = tk.Frame(window, bg=scroll_parchment, padx=20, pady=20)
content_frame.pack(fill=tk.BOTH, expand=True)

# Create description frame with magical border
desc_frame = tk.Frame(content_frame, bg=scroll_parchment, bd=2, relief=tk.GROOVE, padx=15, pady=15)
desc_frame.pack(fill=tk.X, pady=10)

# Multi-line description text with magical theme
description_text = """Transform your repository into magical scrolls for LLM analysis!

This arcane tool creates two powerful artifacts:
üîÆ The Complete Grimoire - All repository files combined
üìú The Insights Tome - Repository structure and metrics"""

description_label = tk.Label(desc_frame, 
                           text=description_text,
                           font=normal_font,
                           bg=scroll_parchment,
                           justify=tk.LEFT,
                           wraplength=550)
description_label.pack(anchor=tk.W)

# Create frame for the repository selection
select_frame = tk.Frame(content_frame, bg=scroll_parchment, pady=10)
select_frame.pack(fill=tk.X)

# Style for the button
button_style = ttk.Style()
button_style.configure("Wizard.TButton", 
                     font=normal_font, 
                     background=potion_green)

# Button to select repository
select_button = ttk.Button(
    select_frame,
    text="üßô‚Äç‚ôÇÔ∏è Select Repository",
    command=select_repo,
    style="Wizard.TButton",
    padding=(20, 10)
)
select_button.pack(pady=10)

# Progress tracking with magical theme
progress_frame = tk.Frame(content_frame, bg=scroll_parchment, pady=5)
progress_frame.pack(fill=tk.X)

# Add a magical cauldron image or text before progress bar
cauldron_label = tk.Label(progress_frame, 
                        text="üß™ Brewing Progress üß™", 
                        font=normal_font, 
                        bg=scroll_parchment)
cauldron_label.pack(pady=5)

progress_var = tk.IntVar()
progress = ttk.Progressbar(progress_frame, 
                          orient=tk.HORIZONTAL, 
                          length=550, 
                          mode='determinate',
                          variable=progress_var)
progress.pack(pady=10)

status_var = tk.StringVar()
status_var.set("Ready to cast analysis spell")
status_label = tk.Label(progress_frame, 
                       textvariable=status_var,
                       font=small_font,
                       bg=scroll_parchment)
status_label.pack()

# A mystical decoration
divider_frame = tk.Frame(content_frame, bg=spell_gold, height=2)
divider_frame.pack(fill=tk.X, pady=15)

# Information text
info_label = tk.Label(content_frame,
                     text="Your arcane analysis will appear as two scrolls in the current directory",
                     font=small_font,
                     bg=scroll_parchment)
info_label.pack(pady=5)

# Footer frame with magical design
footer_frame = tk.Frame(window, bg=mystic_blue, padx=10, pady=8)
footer_frame.pack(fill=tk.X, side=tk.BOTTOM)

# Credits label
credits_label = tk.Label(footer_frame, 
                        text="‚ú® Cloud Potions ¬© 2025 - Making GitHub Repositories LLM-Ready ‚ú®",
                        font=small_font, 
                        fg="white",
                        bg=mystic_blue)
credits_label.pack()

# Run the main event loop
window.mainloop()
